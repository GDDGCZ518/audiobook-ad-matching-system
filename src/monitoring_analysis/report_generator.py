#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç»¼åˆæŠ¥å‘Šç”Ÿæˆå™¨
æ•´åˆè¯„ä¼°æŒ‡æ ‡ã€æ€§èƒ½åˆ†æå’Œä¼˜åŒ–å»ºè®®ï¼Œç”Ÿæˆå®Œæ•´çš„ç³»ç»Ÿåˆ†ææŠ¥å‘Š
"""

import json
import os
from datetime import datetime
from typing import Dict, List, Optional
import logging
from dataclasses import dataclass

@dataclass
class ReportSection:
    """æŠ¥å‘Šç« èŠ‚"""
    title: str
    content: str
    priority: str  # "high", "medium", "low"

class ReportGenerator:
    """ç»¼åˆæŠ¥å‘Šç”Ÿæˆå™¨"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        
    def generate_comprehensive_report(self, evaluation_report: Dict, 
                                   performance_analysis: Dict = None) -> Dict:
        """ç”Ÿæˆç»¼åˆæŠ¥å‘Š"""
        report = {
            "report_info": {
                "title": "æœ‰å£°ä¹¦å¹¿å‘ŠåŒ¹é…ç³»ç»Ÿç»¼åˆè¯„ä¼°æŠ¥å‘Š",
                "generated_at": datetime.now().isoformat(),
                "version": "1.0"
            },
            "executive_summary": self._generate_executive_summary(evaluation_report),
            "performance_overview": self._generate_performance_overview(evaluation_report),
            "detailed_analysis": self._generate_detailed_analysis(evaluation_report),
            "optimization_roadmap": self._generate_optimization_roadmap(performance_analysis),
            "recommendations": self._generate_recommendations(evaluation_report, performance_analysis),
            "next_steps": self._generate_next_steps(evaluation_report, performance_analysis)
        }
        
        return report
    
    def _generate_executive_summary(self, evaluation_report: Dict) -> Dict:
        """ç”Ÿæˆæ‰§è¡Œæ‘˜è¦"""
        summary = evaluation_report.get('summary', {})
        
        return {
            "overall_grade": summary.get('overall_grade', 'N/A'),
            "overall_score": summary.get('overall_score', 0),
            "key_findings": [
                f"ç³»ç»Ÿæ€»ä½“è¯„çº§: {summary.get('overall_grade', 'N/A')}",
                f"ä¼˜ç§€æŒ‡æ ‡: {summary.get('excellent_count', 0)}ä¸ª",
                f"éœ€æ”¹è¿›æŒ‡æ ‡: {summary.get('needs_improvement_count', 0)}ä¸ª",
                f"ä¸»è¦é—®é¢˜: ç‚¹å‡»ç‡å’Œè½¬åŒ–ç‡ä½äºè¡Œä¸šæ ‡å‡†"
            ],
            "business_impact": "å½“å‰æ€§èƒ½æ°´å¹³å¯èƒ½å½±å“å¹¿å‘Šæ”¶å…¥å’Œç”¨æˆ·æ»¡æ„åº¦ï¼Œå»ºè®®ä¼˜å…ˆè§£å†³å…³é”®é—®é¢˜"
        }
    
    def _generate_performance_overview(self, evaluation_report: Dict) -> Dict:
        """ç”Ÿæˆæ€§èƒ½æ¦‚è§ˆ"""
        benchmark_analysis = evaluation_report.get('benchmark_analysis', {})
        
        overview = {
            "metrics_summary": {},
            "strengths": [],
            "weaknesses": [],
            "opportunities": []
        }
        
        for metric_name, analysis in benchmark_analysis.items():
            status = analysis.get('status', 'unknown')
            current_value = analysis.get('current_value', 0)
            benchmark_value = analysis.get('benchmark_value', 0)
            
            overview["metrics_summary"][metric_name] = {
                "current": current_value,
                "benchmark": benchmark_value,
                "status": status,
                "gap": current_value - benchmark_value
            }
            
            if status == "excellent":
                overview["strengths"].append(f"{metric_name}: è¡¨ç°ä¼˜ç§€ï¼Œè¾¾åˆ°è¡Œä¸šé¢†å…ˆæ°´å¹³")
            elif status == "good":
                overview["strengths"].append(f"{metric_name}: è¡¨ç°è‰¯å¥½ï¼Œæ¥è¿‘è¡Œä¸šæ ‡å‡†")
            elif status in ["needs_improvement", "acceptable"]:
                overview["weaknesses"].append(f"{metric_name}: éœ€è¦æ”¹è¿›ï¼Œä½äºè¡Œä¸šæ ‡å‡†")
                overview["opportunities"].append(f"{metric_name}: æœ‰è¾ƒå¤§æå‡ç©ºé—´")
        
        return overview
    
    def _generate_detailed_analysis(self, evaluation_report: Dict) -> Dict:
        """ç”Ÿæˆè¯¦ç»†åˆ†æ"""
        benchmark_analysis = evaluation_report.get('benchmark_analysis', {})
        
        analysis = {
            "metric_analysis": {},
            "trend_analysis": "åŸºäºå½“å‰æ•°æ®ï¼Œç³»ç»Ÿåœ¨ç‚¹å‡»ç‡å’Œè½¬åŒ–ç‡æ–¹é¢æœ‰æ˜¾è‘—æ”¹è¿›ç©ºé—´",
            "risk_assessment": {
                "high_risk": ["ç‚¹å‡»ç‡ä½å½±å“å¹¿å‘Šæ•ˆæœ", "è½¬åŒ–ç‡ä½å½±å“æ”¶å…¥"],
                "medium_risk": ["å“åº”æ—¶é—´å¯èƒ½å½±å“ç”¨æˆ·ä½“éªŒ"],
                "low_risk": ["ç”¨æˆ·æ»¡æ„åº¦è¾¾åˆ°æ ‡å‡†"]
            }
        }
        
        for metric_name, analysis_data in benchmark_analysis.items():
            current_value = analysis_data.get('current_value', 0)
            benchmark_value = analysis_data.get('benchmark_value', 0)
            improvement_percent = analysis_data.get('improvement_percent', 0)
            
            analysis["metric_analysis"][metric_name] = {
                "current_performance": current_value,
                "benchmark_comparison": benchmark_value,
                "gap_analysis": f"å·®è·: {improvement_percent:+.1f}%",
                "improvement_potential": self._assess_improvement_potential(improvement_percent)
            }
        
        return analysis
    
    def _generate_optimization_roadmap(self, performance_analysis: Dict) -> Dict:
        """ç”Ÿæˆä¼˜åŒ–è·¯çº¿å›¾"""
        if not performance_analysis:
            return {"message": "æ— æ€§èƒ½åˆ†ææ•°æ®"}
        
        roadmap = performance_analysis.get('optimization_roadmap', {})
        
        return {
            "timeline": {
                "phase_1": "1-2å‘¨: è§£å†³å…³é”®é—®é¢˜",
                "phase_2": "2-4å‘¨: è§£å†³é«˜ä¼˜å…ˆçº§é—®é¢˜", 
                "phase_3": "4-8å‘¨: è§£å†³ä¸­ä½ä¼˜å…ˆçº§é—®é¢˜"
            },
            "resource_requirements": roadmap.get('resource_requirements', {}),
            "expected_improvements": roadmap.get('estimated_improvement', {}),
            "success_metrics": [
                "ç‚¹å‡»ç‡æå‡åˆ°5%ä»¥ä¸Š",
                "è½¬åŒ–ç‡æå‡åˆ°10%ä»¥ä¸Š",
                "å“åº”æ—¶é—´é™ä½åˆ°500msä»¥ä¸‹"
            ]
        }
    
    def _generate_recommendations(self, evaluation_report: Dict, 
                                performance_analysis: Dict) -> Dict:
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        recommendations = {
            "immediate_actions": [],
            "short_term_improvements": [],
            "long_term_optimizations": [],
            "priority_order": []
        }
        
        # åŸºäºè¯„ä¼°æŠ¥å‘Šç”Ÿæˆå»ºè®®
        if evaluation_report.get('recommendations'):
            recommendations["immediate_actions"].extend(
                evaluation_report['recommendations']
            )
        
        # åŸºäºæ€§èƒ½åˆ†æç”Ÿæˆå»ºè®®
        if performance_analysis and performance_analysis.get('performance_issues'):
            issues = performance_analysis['performance_issues']
            
            for issue in issues:
                priority = issue.get('priority', 3)
                solution = issue.get('solution', '')
                
                if priority == 1:
                    recommendations["immediate_actions"].append(solution)
                elif priority == 2:
                    recommendations["short_term_improvements"].append(solution)
                else:
                    recommendations["long_term_optimizations"].append(solution)
        
        # å»é‡å¹¶æ’åº
        recommendations["immediate_actions"] = list(set(recommendations["immediate_actions"]))
        recommendations["short_term_improvements"] = list(set(recommendations["short_term_improvements"]))
        recommendations["long_term_optimizations"] = list(set(recommendations["long_term_optimizations"]))
        
        # è®¾ç½®ä¼˜å…ˆçº§é¡ºåº
        recommendations["priority_order"] = [
            "è§£å†³å…³é”®æ€§èƒ½é—®é¢˜",
            "ä¼˜åŒ–æ¨èç®—æ³•",
            "æ”¹è¿›ç”¨æˆ·ç•Œé¢",
            "å¢å¼ºç›‘æ§ç³»ç»Ÿ",
            "é•¿æœŸæ¶æ„ä¼˜åŒ–"
        ]
        
        return recommendations
    
    def _generate_next_steps(self, evaluation_report: Dict, 
                            performance_analysis: Dict) -> Dict:
        """ç”Ÿæˆä¸‹ä¸€æ­¥è¡ŒåŠ¨è®¡åˆ’"""
        summary = evaluation_report.get('summary', {})
        overall_score = summary.get('overall_score', 0)
        
        if overall_score >= 3.5:
            status = "excellent"
            next_steps = [
                "ä¿æŒå½“å‰ä¼˜ç§€è¡¨ç°",
                "æŒç»­ç›‘æ§å…³é”®æŒ‡æ ‡",
                "æ¢ç´¢è¿›ä¸€æ­¥ä¼˜åŒ–æœºä¼š"
            ]
        elif overall_score >= 2.5:
            status = "good"
            next_steps = [
                "å®æ–½çŸ­æœŸä¼˜åŒ–è®¡åˆ’",
                "é‡ç‚¹å…³æ³¨éœ€æ”¹è¿›æŒ‡æ ‡",
                "åˆ¶å®šé•¿æœŸä¼˜åŒ–ç­–ç•¥"
            ]
        else:
            status = "needs_improvement"
            next_steps = [
                "ç«‹å³å¯åŠ¨å…³é”®é—®é¢˜ä¿®å¤",
                "åˆ†é…é«˜ä¼˜å…ˆçº§èµ„æº",
                "åˆ¶å®šç´§æ€¥ä¼˜åŒ–è®¡åˆ’"
            ]
        
        return {
            "current_status": status,
            "immediate_actions": next_steps,
            "timeline": "å»ºè®®åœ¨2å‘¨å†…å®Œæˆåˆæ­¥ä¼˜åŒ–",
            "success_criteria": "ç‚¹å‡»ç‡å’Œè½¬åŒ–ç‡æå‡åˆ°è¡Œä¸šæ ‡å‡†æ°´å¹³"
        }
    
    def _assess_improvement_potential(self, improvement_percent: float) -> str:
        """è¯„ä¼°æ”¹è¿›æ½œåŠ›"""
        if improvement_percent >= 100:
            return "æé«˜"
        elif improvement_percent >= 50:
            return "é«˜"
        elif improvement_percent >= 20:
            return "ä¸­ç­‰"
        elif improvement_percent >= 0:
            return "ä½"
        else:
            return "éœ€è¦æ”¹è¿›"
    
    def save_report(self, report: Dict, filepath: str):
        """ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶"""
        try:
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            os.makedirs(os.path.dirname(filepath), exist_ok=True)
            
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(report, f, indent=2, ensure_ascii=False, default=str)
            
            self.logger.info(f"ç»¼åˆæŠ¥å‘Šå·²ä¿å­˜åˆ°: {filepath}")
            
        except Exception as e:
            self.logger.error(f"ä¿å­˜æŠ¥å‘Šå¤±è´¥: {e}")
    
    def generate_markdown_report(self, report: Dict) -> str:
        """ç”ŸæˆMarkdownæ ¼å¼çš„æŠ¥å‘Š"""
        md_content = f"""# {report['report_info']['title']}

**ç”Ÿæˆæ—¶é—´**: {report['report_info']['generated_at']}  
**æŠ¥å‘Šç‰ˆæœ¬**: {report['report_info']['version']}

## ğŸ“Š æ‰§è¡Œæ‘˜è¦

**æ€»ä½“è¯„çº§**: {report['executive_summary']['overall_grade']}  
**æ€»ä½“è¯„åˆ†**: {report['executive_summary']['overall_score']:.2f}/4.0

### å…³é”®å‘ç°
"""
        
        for finding in report['executive_summary']['key_findings']:
            md_content += f"- {finding}\n"
        
        md_content += f"\n**ä¸šåŠ¡å½±å“**: {report['executive_summary']['business_impact']}\n"
        
        # æ€§èƒ½æ¦‚è§ˆ
        md_content += "\n## ğŸ“ˆ æ€§èƒ½æ¦‚è§ˆ\n\n"
        
        overview = report['performance_overview']
        if overview['strengths']:
            md_content += "### âœ… ä¼˜åŠ¿\n"
            for strength in overview['strengths']:
                md_content += f"- {strength}\n"
            md_content += "\n"
        
        if overview['weaknesses']:
            md_content += "### âš ï¸ éœ€æ”¹è¿›\n"
            for weakness in overview['weaknesses']:
                md_content += f"- {weakness}\n"
            md_content += "\n"
        
        # ä¼˜åŒ–è·¯çº¿å›¾
        roadmap = report['optimization_roadmap']
        if roadmap.get('timeline'):
            md_content += "## ğŸ—ºï¸ ä¼˜åŒ–è·¯çº¿å›¾\n\n"
            for phase, description in roadmap['timeline'].items():
                md_content += f"**{phase}**: {description}\n"
            md_content += "\n"
        
        # å»ºè®®
        recommendations = report['recommendations']
        if recommendations['immediate_actions']:
            md_content += "## ğŸš€ ç«‹å³è¡ŒåŠ¨\n\n"
            for action in recommendations['immediate_actions']:
                md_content += f"- {action}\n"
            md_content += "\n"
        
        # ä¸‹ä¸€æ­¥
        next_steps = report['next_steps']
        md_content += f"## ğŸ“‹ ä¸‹ä¸€æ­¥è®¡åˆ’\n\n"
        md_content += f"**å½“å‰çŠ¶æ€**: {next_steps['current_status']}\n"
        md_content += f"**æ—¶é—´çº¿**: {next_steps['timeline']}\n"
        md_content += f"**æˆåŠŸæ ‡å‡†**: {next_steps['success_criteria']}\n\n"
        
        md_content += "### å…·ä½“è¡ŒåŠ¨\n"
        for step in next_steps['immediate_actions']:
            md_content += f"- {step}\n"
        
        return md_content
